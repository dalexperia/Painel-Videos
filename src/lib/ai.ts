import { GoogleGenerativeAI } from "@google/generative-ai";
import Groq from "groq-sdk";

export type AIProvider = 'gemini' | 'groq' | 'ollama';
export type GenerationType = 'title' | 'description' | 'tags' | 'hashtags' | 'autocomplete_tags' | 'autocomplete_hashtags' | 'image_prompt' | 'caption';

interface AIConfig {
  provider: AIProvider;
  apiKey?: string;
  url?: string;
  model?: string;
}

// --- Prompts Otimizados para JSON ---
const getSystemInstruction = (type: GenerationType, context?: string): string => {
  const baseInstruction = `
    Voc√™ √© um assistente de IA especializado em YouTube e Cria√ß√£o de Conte√∫do.
    REGRAS CR√çTICAS:
    1. Responda APENAS com um ARRAY JSON de strings v√°lido.
    2. N√ÉO use Markdown.
    3. N√ÉO inclua explica√ß√µes.
  `;

  switch (type) {
    case 'title':
      return `${baseInstruction}
      OBJETIVO: Gere 5 t√≠tulos virais, curtos e impactantes para um v√≠deo sobre: "${context}".`;
    
    case 'description':
      return `${baseInstruction}
      OBJETIVO: Gere 5 descri√ß√µes curtas e engajadoras para um v√≠deo sobre: "${context}".`;
    
    case 'tags':
      return `${baseInstruction}
      OBJETIVO: Gere 5 listas de tags (separadas por v√≠rgula) para um v√≠deo sobre: "${context}".`;
    
    case 'hashtags':
      return `${baseInstruction}
      OBJETIVO: Gere 5 combina√ß√µes de hashtags para um v√≠deo sobre: "${context}".`;

    case 'autocomplete_tags':
      return `${baseInstruction}
      OBJETIVO: Voc√™ √© um motor de autocomplete inteligente estilo YouTube Studio.
      CONTEXTO DO V√çDEO: O v√≠deo √© sobre "${context}".
      TAREFA: O usu√°rio digitou um termo parcial. Retorne 5 a 8 sugest√µes de tags que completem esse termo e sejam altamente relevantes para o contexto do v√≠deo.
      Exemplo: Se o contexto √© "Salmos" e o termo √© "salm", retorne ["salmo 91", "salmo 23", "salmos poderosos"].`;

    case 'autocomplete_hashtags':
      return `${baseInstruction}
      OBJETIVO: Voc√™ √© um motor de autocomplete de hashtags.
      CONTEXTO DO V√çDEO: O v√≠deo √© sobre "${context}".
      TAREFA: O usu√°rio digitou um termo parcial. Retorne 5 a 8 hashtags (com #) que completem esse termo.`;

    case 'image_prompt':
      return `${baseInstruction}
      OBJETIVO: Voc√™ √© um Engenheiro de Prompt (Prompt Engineer) especialista em Midjourney e DALL-E 3.
      TAREFA: Melhore a ideia b√°sica do usu√°rio para criar uma imagem visualmente impressionante.
      CONTEXTO: O usu√°rio quer uma imagem sobre: "${context}".
      SA√çDA: Gere 3 varia√ß√µes de prompts detalhados. Para cada varia√ß√£o, forne√ßa a vers√£o em INGL√äS (para a IA de imagem) e uma tradu√ß√£o correspondente em PORTUGU√äS (para exibi√ß√£o ao usu√°rio).
      Formato de Sa√≠da: Um array de objetos, onde cada objeto tem as chaves 'pt' e 'en'.
      Exemplo de Sa√≠da: [{"pt": "Um gato preto m√≠stico, cercado por um halo de luz suave e et√©rea, em um cen√°rio de floresta iluminada pela lua, com detalhes e texturas intrincados, no estilo de uma ilustra√ß√£o de fantasia, resolu√ß√£o 4k", "en": "A mystical black cat, surrounded by a halo of soft, ethereal light, set against a backdrop of a moonlit forest, with intricate details and textures, in the style of a fantasy illustration, 4k resolution"}]`;
    
    case 'caption':
      return `${baseInstruction}
      OBJETIVO: Voc√™ √© um especialista em marketing de conte√∫do para Instagram.
      TAREFA: Gere exatamente 3 sugest√µes de legendas criativas, detalhadas e envolventes para um post no Instagram.
      CONTEXTO: O post √© sobre: "${context}".
      SA√çDA: As legendas devem ser em portugu√™s, ter um bom tamanho (2-3 frases), incluir emojis relevantes e uma variedade de hashtags populares e espec√≠ficas (5-10 hashtags por sugest√£o).
      Formato de Sa√≠da: Um array de strings.
      Exemplo de Sa√≠da: ["Descubra a sabedoria de Marco Aur√©lio! üí° Fil√≥sofo e imperador romano, suas palavras ainda nos inspiram hoje a viver com prop√≥sito e resili√™ncia. Uma verdadeira fonte de inspira√ß√£o para a vida moderna. #MarcoAurelio #FilosofiaEst√≥ica #SabedoriaAntiga #Inspira√ß√£oDi√°ria #PensamentosProfundos", "A vida √© um presente, aproveite cada momento! üòä Marco Aur√©lio nos lembra da import√¢ncia de viver no presente, valorizando cada instante e buscando a serenidade em meio aos desafios. Viva intensamente! #Inspira√ß√£o #Motiva√ß√£o #VivaOAgora #Gratid√£o #Mindfulness #DesenvolvimentoPessoal", "A for√ßa vem da calma e da determina√ß√£o. üôè Marco Aur√©lio nos ensina a encontrar a for√ßa interior para superar obst√°culos, mantendo a mente tranquila e o foco nos objetivos. A verdadeira resili√™ncia nasce da paz interior. #Autoajuda #DesenvolvimentoPessoal #For√ßaInterior #Resili√™ncia #PazDeEsp√≠rito #FocoNoObjetivo"]`;
    
    default:
      return baseInstruction;
  }
};

// --- Parsers e Limpeza ---
const parseAIResponse = (text: string, type: GenerationType): string[] | { pt: string; en: string }[] => {
  try {
    let cleanText = text.replace(/```json/g, '').replace(/```/g, '').trim();
    
    const firstBracket = cleanText.indexOf('[');
    const lastBracket = cleanText.lastIndexOf(']');
    
    if (firstBracket !== -1 && lastBracket !== -1) {
      cleanText = cleanText.substring(firstBracket, lastBracket + 1);
    }

    const parsed = JSON.parse(cleanText);

    if (type === 'image_prompt') {
      if (Array.isArray(parsed) && parsed.every(item => typeof item === 'object' && item !== null && 'pt' in item && 'en' in item)) {
        return parsed.map(item => ({ pt: String(item.pt).trim(), en: String(item.en).trim() }));
      }
      throw new Error("Resposta n√£o √© um array de objetos com chaves 'pt' e 'en'.");
    } else if (type === 'caption') {
      if (Array.isArray(parsed) && parsed.every(item => typeof item === 'string')) {
        return parsed.map(item => String(item).trim());
      }
      throw new Error("Resposta n√£o √© um array de strings para legenda.");
    } else {
      // Para outros tipos que esperam array de strings
      if (Array.isArray(parsed) && parsed.every(item => typeof item === 'string')) {
        return parsed.map(item => String(item).trim());
      }
      throw new Error("Resposta n√£o √© um array de strings.");
    }

  } catch (e) {
    console.warn("Falha ao fazer parse do JSON da IA. Tentando fallback manual.", e);
    const lines = text
      .split('\n')
      .map(l => l.replace(/^\d+\.|-|\*|"|,|\[|\]/g, '').trim())
      .filter(l => l.length > 1);
    
    if (type === 'image_prompt') {
      return lines.map(line => ({ pt: line, en: line }));
    } else {
      return lines;
    }
  }
};

// --- Implementa√ß√µes dos Provedores ---

const generateGemini = async (apiKey: string, prompt: string, type: GenerationType) => {
  const genAI = new GoogleGenerativeAI(apiKey);
  const model = genAI.getGenerativeModel({ 
    model: "gemini-2.0-flash",
    generationConfig: { responseMimeType: "application/json" }
  });
  
  const systemPrompt = getSystemInstruction(type, prompt);
  
  const result = await model.generateContent(systemPrompt);
  return result.response.text();
};

const generateGroq = async (apiKey: string, prompt: string, type: GenerationType, modelId: string = 'llama3-70b-8192') => {
  const groq = new Groq({ apiKey, dangerouslyAllowBrowser: true }); 
  
  const completion = await groq.chat.completions.create({
    messages: [
      { role: "system", content: getSystemInstruction(type, prompt) },
      { role: "user", content: "Gere o JSON agora." }
    ],
    model: modelId,
    temperature: 0.7, // Temperatura um pouco maior para criatividade nos prompts
    response_format: { type: "json_object" }
  });

  return completion.choices[0]?.message?.content || "[]";
};

const generateOllama = async (url: string, apiKey: string | undefined, prompt: string, type: GenerationType, modelId: string = 'llama3') => {
  const baseUrl = url.replace(/\/$/, '');
  const endpoint = `${baseUrl}/api/generate`;
  
  const fullPrompt = `${getSystemInstruction(type, prompt)}\nResponda apenas com o JSON.`;

  const headers: Record<string, string> = { 'Content-Type': 'application/json' };
  if (apiKey && apiKey.trim() !== '') headers['Authorization'] = `Bearer ${apiKey}`;

  const response = await fetch(endpoint, {
    method: 'POST',
    headers,
    body: JSON.stringify({ 
      model: modelId, 
      prompt: fullPrompt, 
      stream: false,
      format: "json"
    })
  });

  if (!response.ok) throw new Error(`Erro Ollama: ${response.statusText}`);
  const data = await response.json();
  return data.response;
};

// --- Fun√ß√£o Principal ---
export const generateContentAI = async (
  config: AIConfig,
  prompt: string,
  type: GenerationType,
  extraContext?: string
): Promise<string[] | { pt: string; en: string }[]> => {
  
  let finalPrompt = prompt;
  let contextForSystem = prompt;

  // Limpeza da chave de API (Trim)
  const cleanApiKey = config.apiKey ? config.apiKey.trim() : undefined;

  if (type === 'autocomplete_tags' || type === 'autocomplete_hashtags') {
    if (!prompt || prompt.length < 2) return [];
    contextForSystem = extraContext || "V√≠deo Gen√©rico";
    finalPrompt = `Termo parcial digitado pelo usu√°rio: "${prompt}"`;
  }

  console.log(`[AI Service] Provider: ${config.provider} | Type: ${type}`);

  let rawResult = "";

  try {
    const effectivePrompt = (type.includes('autocomplete')) 
      ? `${contextForSystem}. Termo parcial a completar: "${prompt}"`
      : finalPrompt;

    switch (config.provider) {
      case 'gemini':
        if (!cleanApiKey) throw new Error("Chave Gemini n√£o configurada.");
        rawResult = await generateGemini(cleanApiKey, effectivePrompt, type);
        break;
      case 'groq':
        if (!cleanApiKey) throw new Error("Chave Groq n√£o configurada.");
        rawResult = await generateGroq(cleanApiKey, effectivePrompt, type, config.model || 'llama3-70b-8192');
        break;
      case 'ollama':
        if (!config.url) throw new Error("URL do Ollama n√£o configurada.");
        rawResult = await generateOllama(config.url, cleanApiKey, effectivePrompt, type, config.model || 'llama3');
        break;
      default:
        throw new Error("Provedor desconhecido.");
    }

    const variations = parseAIResponse(rawResult, type);
    return variations;

  } catch (error: any) {
    console.error(`Erro na gera√ß√£o (${config.provider}):`, error);
    
    // Tratamento de erro mais amig√°vel para o usu√°rio
    let friendlyMessage = error.message;
    
    if (error.message.includes('401') || error.message.includes('invalid_api_key')) {
      friendlyMessage = "Chave de API inv√°lida (401). Verifique se a chave est√° correta e sem espa√ßos.";
    } else if (error.message.includes('429')) {
      friendlyMessage = "Limite de requisi√ß√µes excedido (429). Tente novamente mais tarde.";
    }

    if (type.includes('autocomplete')) return [];
    throw new Error(friendlyMessage);
  }
};
